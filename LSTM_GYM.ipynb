{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72a9ae4-88a3-4ba7-8e52-acd75dacdd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 07:00:44.805594: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-16 07:00:45.473699: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, LeakyReLU, TimeDistributed, Input, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from datetime import datetime\n",
    "import os\n",
    "from TrainingProgress import TrainingProgress\n",
    "\n",
    "main_log_dir = './logs'\n",
    "main_model_save_dir = './ModelsSave/'\n",
    "file_path = './Data/xmrusd.csv'\n",
    "log_dir = os.path.join(main_log_dir)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "\n",
    "DELKA_SEKVENCE = 30\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deccd8fb-3e69-451a-8202-21c5a166996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            time   open  close   high    low      volume\n",
      "0  1480530840000  7.649  7.649  7.649  7.649    0.100000\n",
      "1  1480530900000  7.681  7.681  7.681  7.681    1.000000\n",
      "2  1480531140000  7.833  7.968  7.968  7.833   51.000000\n",
      "3  1480531260000  8.000  8.000  8.000  8.000   23.328046\n",
      "4  1480531380000  8.000  8.000  8.000  8.000   76.671954\n",
      "5  1480531620000  8.217  8.217  8.217  8.217    0.100000\n",
      "6  1480531740000  8.206  8.206  8.206  8.206    0.100000\n",
      "7  1480531800000  8.217  8.218  8.218  8.206    0.300000\n",
      "8  1480531860000  7.004  8.250  8.250  7.004  100.100000\n",
      "9  1480531980000  8.500  8.500  8.500  8.500  100.000000\n",
      "        open   close    high     low      EMA_5     SMA_15        RSI  \\\n",
      "2000  13.000  13.000  13.000  13.000  12.999082  12.980667  63.521744   \n",
      "2001  12.855  12.855  12.855  12.855  12.951054  12.976200  44.432884   \n",
      "2002  12.842  12.842  12.842  12.842  12.914703  12.973733  43.180030   \n",
      "2003  12.849  12.849  12.849  12.849  12.892802  12.969867  44.094128   \n",
      "2004  12.999  13.032  13.032  12.999  12.939201  12.971933  61.521936   \n",
      "2005  13.032  13.032  13.032  13.032  12.970134  12.974000  61.521936   \n",
      "\n",
      "        STOCH_K    STOCH_D      MACD  MACD_SIGNAL  MACD_HIST  TargetNextClose  \\\n",
      "2000  21.260478  24.196502  0.064552     0.066263  -0.001712           12.855   \n",
      "2001  12.989801  19.433055  0.050078     0.063026  -0.012948           12.842   \n",
      "2002   6.494901  13.581727  0.037130     0.057847  -0.020717           12.849   \n",
      "2003   1.467505   6.984069  0.027121     0.051702  -0.024580           13.032   \n",
      "2004  34.800839  14.254415  0.033569     0.048075  -0.014506           13.032   \n",
      "2005  68.134172  34.800839  0.038238     0.046108  -0.007870           13.036   \n",
      "\n",
      "      Target  TargetClass  \n",
      "2000  -0.145            0  \n",
      "2001  -0.013            0  \n",
      "2002   0.007            1  \n",
      "2003   0.183            1  \n",
      "2004   0.033            1  \n",
      "2005   0.004            1  \n",
      "Train data shape: (908784, 15)\n",
      "Validation data shape: (194739, 15)\n",
      "Test data shape: (194740, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(file_path, parse_dates=['time'], date_format=lambda x: pd.to_datetime(x, unit='ms'))\n",
    "print(df.head(10))\n",
    "\n",
    "# Adding your indicators\n",
    "df['EMA_5'] = ta.ema(df['close'], length=5)\n",
    "df['SMA_15'] = ta.sma(df['close'], length=15)\n",
    "df['RSI'] = ta.rsi(df['close'], length=14)\n",
    "stoch = ta.stoch(df['high'], df['low'], df['close'])\n",
    "df['STOCH_K'] = stoch['STOCHk_14_3_3']\n",
    "df['STOCH_D'] = stoch['STOCHd_14_3_3']\n",
    "macd = ta.macd(df['close'])\n",
    "df['MACD'] = macd['MACD_12_26_9']\n",
    "df['MACD_SIGNAL'] = macd['MACDs_12_26_9']\n",
    "df['MACD_HIST'] = macd['MACDh_12_26_9']\n",
    "\n",
    "#Target, TargetNextClose, and TargetClass\n",
    "df['TargetNextClose'] = df['close'].shift(-1)\n",
    "df['Target'] = df['TargetNextClose'] - df['open']\n",
    "df['TargetClass'] = df['Target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(['index', 'volume', 'time'], axis=1, inplace=True)\n",
    "\n",
    "print(df.iloc[2000:2006])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "\n",
    "train_size = int(len(df) * 0.7)\n",
    "val_size = int(len(df) * 0.15)\n",
    "test_size = len(df) - train_size - val_size\n",
    "\n",
    "train_data = df[:train_size]\n",
    "val_data = df[train_size:train_size + val_size]\n",
    "test_data = df[train_size + val_size:]\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e7f3f9-747d-4df9-9900-88599163ce40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m15\u001b[0m)         │            \u001b[38;5;34m60\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m6,144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │            \u001b[38;5;34m33\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,549</span> (29.49 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,549\u001b[0m (29.49 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,391</span> (28.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,391\u001b[0m (28.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158</span> (632.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m158\u001b[0m (632.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "      EMA_5    SMA_15       RSI   STOCH_K   STOCH_D      MACD  MACD_SIGNAL  \\\n",
      "0  0.003384  0.003438  0.567465  0.420279  0.240602  0.646170     0.641149   \n",
      "1  0.003282  0.003399  0.492870  0.374032  0.311534  0.645550     0.640509   \n",
      "2  0.003054  0.003367  0.456042  0.374032  0.389447  0.644470     0.639751   \n",
      "3  0.003068  0.003303  0.499212  0.205420  0.317828  0.644204     0.639085   \n",
      "4  0.002981  0.003212  0.476098  0.157853  0.245768  0.643641     0.638423   \n",
      "\n",
      "   MACD_HIST  \n",
      "0   0.496371  \n",
      "1   0.496220  \n",
      "2   0.495143  \n",
      "3   0.495977  \n",
      "4   0.496025  \n",
      "\u001b[1m56799/56799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 10ms/step - loss: 0.0223 - mean_absolute_error: 0.0730 - val_loss: 1.7531e-04 - val_mean_absolute_error: 0.0112 - learning_rate: 0.0010\n",
      "Saving final model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = (DELKA_SEKVENCE, train_data.shape[1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(Dense(32)))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mean_absolute_error'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=f'{main_model_save_dir}/best_modelV2.epoch{{epoch:02d}}-val_loss{{val_loss:.2f}}.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_freq='epoch'\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "def data_generator(data, seq_length, batch_size):\n",
    "    data_length = len(data)\n",
    "    indices = np.arange(data_length - seq_length - 1)\n",
    "    np.random.shuffle(indices)\n",
    "    while True:\n",
    "        X, y = [], []\n",
    "        for i in indices:\n",
    "            X.append(data.iloc[i:i + seq_length].values)\n",
    "            y.append(data.iloc[i + seq_length, -3])\n",
    "            if len(X) == batch_size:\n",
    "                yield np.array(X), np.array(y).reshape(-1, 1)\n",
    "                X, y = [], []\n",
    "\n",
    "steps_per_epoch = len(train_data) // BATCH_SIZE\n",
    "validation_steps = len(val_data) // BATCH_SIZE\n",
    "\n",
    "tensorboard_callback = TrainingProgress(total_epochs=EPOCHS, total_batches=steps_per_epoch, log_dir=log_dir, update_freq=100)\n",
    "\n",
    "history = model.fit(\n",
    "    data_generator(train_data, DELKA_SEKVENCE, BATCH_SIZE),\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=data_generator(val_data, DELKA_SEKVENCE, BATCH_SIZE),\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[tensorboard_callback, checkpoint_callback, early_stopping_callback, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "print(\"Saving final model...\", flush=True)\n",
    "model.save(f'{main_model_save_dir}/final_modelV2.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
